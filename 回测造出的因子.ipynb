{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"C:\\\\Users\\\\roderickzzc\\\\Desktop\\\\Quant project\\\\data\\\\\"\n",
    "stockname=\"close\"\n",
    "close = pd.read_csv(csv_path + stockname + \".csv\", index_col = 0, parse_dates = True)\n",
    "stockname=\"open\"\n",
    "op = pd.read_csv(csv_path + stockname + \".csv\", index_col = 0, parse_dates = True)\n",
    "stockname=\"high\"\n",
    "high = pd.read_csv(csv_path + stockname + \".csv\", index_col = 0, parse_dates = True)\n",
    "stockname=\"low\"\n",
    "low = pd.read_csv(csv_path + stockname + \".csv\", index_col = 0, parse_dates = True)\n",
    "stockname=\"TURNOVER_VALUE\"\n",
    "turnover = pd.read_csv(csv_path + stockname + \".csv\", index_col = 0, parse_dates = True)\n",
    "stockname=\"vol\"\n",
    "vol = pd.read_csv(csv_path + stockname + \".csv\", index_col = 0, parse_dates = True)\n",
    "\n",
    "vol=vol.loc['2007-01-04':'2018-08-01']/1000000\n",
    "turnover=turnover.loc['2007-01-04':'2018-08-01']/1000000\n",
    "turnover=turnover[vol.columns]\n",
    "high=high.loc['2007-01-04':'2018-08-01']\n",
    "low=low.loc['2007-01-04':'2018-08-01']\n",
    "op=op.loc['2007-01-04':'2018-08-01']\n",
    "close=close.loc['2007-01-04':'2018-08-01']\n",
    "\n",
    "forward_day = 5\n",
    "stockforward = close.shift(periods = -forward_day, freq = None, axis = 0)\n",
    "stockforwardreturn = (stockforward - close) / close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockforwardreturn\n",
    "#stockforwardreturn=stockforwardreturn.set_index(close.index).set_axis(close.columns)\n",
    "stockforwardreturn.to_csv(os.path.join(csv_path, '5DForward.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"C:\\\\Users\\\\roderickzzc\\\\Desktop\\\\Data\\\\Backtest\\\\\"\n",
    "indexclose = \"IndexClosePrice\"\n",
    "index = pd.read_csv(csv_path + indexclose + \".csv\", index_col = 0, parse_dates = True)\n",
    "indexforward = index.shift(periods = -forward_day, freq = None, axis = 0)\n",
    "indexforwardreturn = (indexforward - index) / index\n",
    "indexforwardreturn=indexforwardreturn.iloc[:-6].set_index(close.index)\n",
    "indexforwardreturn.to_csv(os.path.join('C:\\\\Users\\\\roderickzzc\\\\Desktop\\\\Quant project\\\\data\\\\', 'mkt_5DForward.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rank(data):\n",
    "    return pd.DataFrame.rank(close,axis=1)\n",
    "\n",
    "def _rolling_rank(data):\n",
    "    value = stats.rankdata(data,axis=0)[-1]\n",
    "    return value\n",
    "\n",
    "def _cube(data):\n",
    "    return np.square(data)*data\n",
    "\n",
    "def _square(data):\n",
    "    return np.square(data)\n",
    "\n",
    "def _delta(data):\n",
    "    delta=np.diff(data,axis=0)\n",
    "    delta=np.insert(delta, 0, 0, axis=0)\n",
    "    return pd.DataFrame(delta).set_index(data.index).set_axis(data.columns, axis=1,inplace=False)\n",
    "\n",
    "def _delay(data,n):\n",
    "    period=n\n",
    "    value = data.shift(period)\n",
    "    value = np.nan_to_num(value)\n",
    "    return pd.DataFrame(value).set_index(data.index).set_axis(data.columns, axis=1,inplace=False)\n",
    "        \n",
    "def _corr(data1,data2,n):\n",
    "    return data1.rolling(n).corr(data2)\n",
    "\n",
    "def _cov(data1,data2,n):\n",
    "    return data1.rolling(n).cov(data2)\n",
    "    \n",
    "def _ts_sum(data,n):\n",
    "    dataa=data.rolling(n).sum()\n",
    "    dataa=np.nan_to_num(dataa)\n",
    "    return pd.DataFrame(dataa).set_index(data.index).set_axis(data.columns, axis=1,inplace=False)\n",
    "        \n",
    "def _sma(data,n):\n",
    "    dataa=data.rolling(n).mean()\n",
    "    dataa=np.nan_to_num(dataa)\n",
    "    return pd.DataFrame(dataa).set_index(data.index).set_axis(data.columns, axis=1,inplace=False)\n",
    "\n",
    "def _stddev(data,n): \n",
    "    dataa=data.rolling(n).std()\n",
    "    dataa=np.nan_to_num(dataa)\n",
    "    return pd.DataFrame(dataa).set_index(data.index).set_axis(data.columns, axis=1,inplace=False)\n",
    "\n",
    "def _ts_rank(data,n):\n",
    "    dataa=data.rolling(n).apply(_rolling_rank)\n",
    "    dataa=np.nan_to_num(dataa)\n",
    "    return pd.DataFrame(dataa).set_index(data.index).set_axis(data.columns, axis=1,inplace=False)\n",
    "    \n",
    "def _ts_argmin(data,n):\n",
    "    dataa=data.rolling(n).apply(np.argmin)\n",
    "    dataa=np.nan_to_num(dataa)\n",
    "    return pd.DataFrame(dataa).set_index(data.index).set_axis(data.columns, axis=1,inplace=False)\n",
    "\n",
    "def _ts_argmax(data,n):\n",
    "    dataa=data.rolling(n).apply(np.argmax)\n",
    "    dataa=np.nan_to_num(dataa)\n",
    "    return pd.DataFrame(dataa).set_index(data.index).set_axis(data.columns, axis=1,inplace=False)\n",
    "        \n",
    "def _ts_min(data,n):\n",
    "    dataa=data.rolling(n).min()\n",
    "    dataa=np.nan_to_num(dataa)\n",
    "    return pd.DataFrame(dataa).set_index(data.index).set_axis(data.columns, axis=1,inplace=False)\n",
    "        \n",
    "def _ts_max(data,n):\n",
    "    dataa=data.rolling(n).min()\n",
    "    dataa=np.nan_to_num(dataa)\n",
    "    return pd.DataFrame(dataa).set_index(data.index).set_axis(data.columns, axis=1,inplace=False)\n",
    "        \n",
    "def _ts_argmaxmin(data,n):\n",
    "    return _ts_argmax(data,n) - _ts_argmin(data,n)\n",
    "\n",
    "def protectedDiv(data1,data2):\n",
    "    df=data1/data2\n",
    "    return df\n",
    "\n",
    "def linear_weight(d):\n",
    "    w = list([n/sum(range(1,d+1)) for n in range(1,d+1)])\n",
    "    def g(x):\n",
    "        return sum(w*x) \n",
    "    return g\n",
    "\n",
    "def linear_decay(data,n):\n",
    "    return data.rolling(window=n).apply(linear_weight(n))\n",
    "\n",
    "def exponential_average(data):\n",
    "    return data.ewm(com=0.5).mean()\n",
    "\n",
    "def iden(data):\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%cd C:\\\\Users\\\\roderickzzc\\\\Desktop\\\\Data\\\\Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result_path =  'C:\\\\Users\\\\roderickzzc\\\\Desktop\\\\Data\\\\New_factors\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha1=vol+linear_decay(vol, 7)\n",
    "alpha1.to_csv(os.path.join(save_result_path, 'alpha1.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha2=linear_decay(op, 2)/(high-low)\n",
    "alpha2.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "alpha2.to_csv(os.path.join(save_result_path, 'alpha2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha3=vol/_ts_rank(op, 20)\n",
    "alpha3.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "alpha3.to_csv(os.path.join(save_result_path, 'alpha3.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha4=_cube(close)-_corr(close, turnover, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha4.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "alpha4.to_csv(os.path.join(save_result_path, 'alpha4.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha5=linear_decay(vol, 14) \n",
    "alpha5.to_csv(os.path.join(save_result_path, 'alpha5.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha6=(vol/turnover)/_ts_sum(high, 2)\n",
    "alpha6.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "alpha6.to_csv(os.path.join(save_result_path, 'alpha6.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha7=vol+_corr(close, op, 6)\n",
    "alpha7.replace([np.inf, -np.inf], np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha8=vol\n",
    "alpha8.to_csv(os.path.join(save_result_path, 'alpha8.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha9=close\n",
    "alpha9.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "alpha9.to_csv(os.path.join(save_result_path, 'alpha9.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run helper.py\n",
    "%run backtestlite.py\n",
    "\n",
    "working_directory = 'C:\\\\Users\\\\roderickzzc\\\\Desktop\\\\Quant project\\\\data\\\\'\n",
    "factor_path_all = 'C:\\\\Users\\\\roderickzzc\\\\Desktop\\\\Data\\\\New_factors\\\\'\n",
    "\n",
    "direction = \"Descending\"\n",
    "\n",
    "#start = '2007-01-04' \n",
    "#end = '2017-01-16'\n",
    "start = '2017-01-17' \n",
    "end = '2018-08-01'\n",
    "quantile = 10\n",
    "cycle = 5 # Adjustment Cycle (trading frequency), delay for holidays. \n",
    "win = 48 # 48 weeks in a year\n",
    "year = 2017 # Beginning year of result display (graphs).\n",
    "\n",
    "#Import stock 5days forward return.\n",
    "fwdrtn = pd.read_csv(os.path.join(working_directory, \"5DForward.csv\"), index_col = 0, parse_dates = True).loc[start:end][::cycle]\n",
    "#Import market 5days forward return.\n",
    "mkt_index = pd.read_csv(os.path.join(working_directory, \"mkt_5DForward.csv\"), index_col = 0, parse_dates = True).loc[str(start):str(end),\"SH000300\"][::cycle]\n",
    "status = pd.DataFrame(1, index = fwdrtn.index, columns = fwdrtn.columns)\n",
    "statuslimit = pd.DataFrame(1, index = fwdrtn.index, columns = fwdrtn.columns)\n",
    "\n",
    "# Revise the factor name (name of .csv file)\n",
    "factor = \"alpha7\"\n",
    "\n",
    "Type = \"LS\" # this stand for long-short strategy. \n",
    "\n",
    "\n",
    "def singlefactor(factor,factor_path_all,Type,direction,fwdrtn,mkt_index,cycle, start, end, quantile,win,year, statuslimit):\n",
    "    factor_path = os.path.join(factor_path_all, factor + '.csv')\n",
    "\n",
    "    Type1 = \"LS\"\n",
    "    B = Backtestlite(factor_path, direction, fwdrtn, mkt_index, factor_path_all, cycle, start, end, quantile, statuslimit)\n",
    "    B.run(Type1)\n",
    "\n",
    "    # Drawing\n",
    "    pic = DrawPicture(factor,direction, B.data,  B.fwdrtn, B.data.index , mkt_index,  B.rtn_data, B.coverage, B.turnover, factor_path_all, Type1)    \n",
    "    pic.main(win,year,B.rtn_data.columns)\n",
    "    \n",
    "# Calculate performances and do the plot\n",
    "singlefactor(factor,factor_path_all,Type, direction,fwdrtn,mkt_index,cycle, start, end, quantile,win,year, statuslimit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
